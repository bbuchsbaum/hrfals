% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tune_beta_l1_hrfals.R
\name{tune_beta_l1_hrfals}
\alias{tune_beta_l1_hrfals}
\title{Tune L1 Penalty for Sparse Beta Estimation}
\usage{
tune_beta_l1_hrfals(
  fmri_data_obj_subset,
  event_model,
  hrf_basis,
  l1_grid = 10^seq(-3, 0, length.out = 7),
  alpha_value = 1,
  n_outer_iterations_cfals = 1,
  other_hrfals_args = list(lam_beta = 0.01, lam_h = 0.01),
  cv_voxel_subset_train_prop = 0.7,
  seed = NULL
)
}
\arguments{
\item{fmri_data_obj_subset}{Numeric matrix or `fmri_dataset` containing
a subset of voxels used for tuning.}

\item{event_model}{An `event_model` describing the stimuli.}

\item{hrf_basis}{HRF basis object.}

\item{l1_grid}{Numeric vector of L1 penalty strengths to evaluate.}

\item{alpha_value}{Elastic net mixing parameter passed to `hrfals`.}

\item{n_outer_iterations_cfals}{Number of CF-ALS iterations to run
during tuning.}

\item{other_hrfals_args}{Named list of additional arguments forwarded
to [hrfals()].}

\item{cv_voxel_subset_train_prop}{Proportion of voxels used for the
training split. Remaining voxels are used for testing.}

\item{seed}{Optional random seed for reproducible splits.}
}
\value{
Data frame with columns `l1`, `train_mse`, `test_mse` and a
  `best` flag. The attribute `best_l1` holds the optimal penalty.
}
\description{
Helper performing a simple grid search over the L1 penalty used for
sparse beta estimation in `hrfals`. A subset of voxels is split into
train and test sets. For each value in `l1_grid` the CF-ALS solver is
run on the training voxels and prediction error on the test voxels is
computed. The best L1 value is returned along with the full results
table.
}
\examples{
\dontrun{
res <- tune_beta_l1_hrfals(Y_small, emod, HRF_SPMG3)
res$best_l1
}
}
